{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavPhanindra/Deep-Learning-PyTorch/blob/main/23357_MTCS_205P_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P8WcNwtbgfM"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci4sQkUSOZdO",
        "outputId": "97ed4699-fd9a-4a2a-a6e2-f65b46f2b3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=8016dfb719a26467a232a4fa24e0024cfe0df8fd829d7968185d4447255ce62e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz\n",
        "!pip install tensorboard\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7gdBlqfv_-p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "\n",
        "from pyngrok import ngrok\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchviz import make_dot\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gsygWWJebsq"
      },
      "source": [
        "# Data Loading and info about Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtS5JpmwegFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903c9ab6-2e45-4939-f2e0-ff46aea2da1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16625168.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 310193.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5597450.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 13312131.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QZxzgnViBA0"
      },
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "#Defining labels for different classes of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "O3t2B97Se-1i",
        "outputId": "90c42ee7-9afa-4810-9f8e-0c238e8f30dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "img,label = training_data[1]\n",
        "img = img.reshape(28,28)\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.title(labels_map[label])\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQmu2EJmy3H3",
        "outputId": "6c2eae92-4bc2-4a5c-f8c9-5a774245c4fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1608, 0.7373, 0.4039, 0.2118, 0.1882, 0.1686, 0.3412, 0.6588,\n",
              "         0.5216, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.1922, 0.5333,\n",
              "         0.8588, 0.8471, 0.8941, 0.9255, 1.0000, 1.0000, 1.0000, 1.0000, 0.8510,\n",
              "         0.8431, 0.9961, 0.9059, 0.6275, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6902, 0.8706, 0.8784,\n",
              "         0.8314, 0.7961, 0.7765, 0.7686, 0.7843, 0.8431, 0.8000, 0.7922, 0.7882,\n",
              "         0.7882, 0.7882, 0.8196, 0.8549, 0.8784, 0.6431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.8588, 0.7843, 0.7765,\n",
              "         0.7922, 0.7765, 0.7804, 0.7804, 0.7882, 0.7686, 0.7765, 0.7765, 0.7843,\n",
              "         0.7843, 0.7843, 0.7843, 0.7882, 0.7843, 0.8824, 0.1608, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.8588, 0.7804, 0.7961, 0.7961,\n",
              "         0.8314, 0.9333, 0.9725, 0.9804, 0.9608, 0.9765, 0.9647, 0.9686, 0.9882,\n",
              "         0.9725, 0.9216, 0.8118, 0.7961, 0.7961, 0.8706, 0.5490, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.8863, 0.8078, 0.8000, 0.8118,\n",
              "         0.8000, 0.3961, 0.2941, 0.1843, 0.2863, 0.1882, 0.1961, 0.1765, 0.2000,\n",
              "         0.2471, 0.4431, 0.8706, 0.7922, 0.8078, 0.8627, 0.8784, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8706, 0.8196, 0.7961, 0.8431,\n",
              "         0.7843, 0.0000, 0.2745, 0.3843, 0.0000, 0.4039, 0.2314, 0.2667, 0.2784,\n",
              "         0.1922, 0.0000, 0.8588, 0.8078, 0.8392, 0.8235, 0.9804, 0.1490, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9686, 0.8549, 0.8314, 0.8235, 0.8431,\n",
              "         0.8392, 0.0000, 0.9961, 0.9529, 0.5451, 1.0000, 0.6824, 0.9843, 1.0000,\n",
              "         0.8039, 0.0000, 0.8431, 0.8510, 0.8392, 0.8157, 0.8627, 0.3725, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.1765, 0.8863, 0.8392, 0.8392, 0.8431, 0.8784,\n",
              "         0.8039, 0.0000, 0.1647, 0.1373, 0.2353, 0.0627, 0.0667, 0.0471, 0.0510,\n",
              "         0.2745, 0.0000, 0.7412, 0.8471, 0.8314, 0.8078, 0.8314, 0.6118, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.6431, 0.9216, 0.8392, 0.8275, 0.8627, 0.8471,\n",
              "         0.7882, 0.2039, 0.2784, 0.3490, 0.3686, 0.3255, 0.3059, 0.2745, 0.2980,\n",
              "         0.3608, 0.3412, 0.8078, 0.8118, 0.8706, 0.8353, 0.8588, 0.8157, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.4157, 0.7333, 0.8745, 0.9294, 0.9725, 0.8275,\n",
              "         0.7765, 0.9882, 0.9804, 0.9725, 0.9608, 0.9725, 0.9882, 0.9922, 0.9804,\n",
              "         0.9882, 0.9373, 0.7882, 0.8314, 0.8824, 0.8431, 0.7569, 0.4431, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2118, 0.6235, 0.8706,\n",
              "         0.7569, 0.8157, 0.7529, 0.7725, 0.7843, 0.7843, 0.7843, 0.7843, 0.7882,\n",
              "         0.7961, 0.7647, 0.8235, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.8824,\n",
              "         0.7529, 0.8392, 0.7961, 0.8078, 0.8000, 0.8000, 0.8039, 0.8078, 0.8000,\n",
              "         0.8314, 0.7725, 0.8549, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0235, 0.0000, 0.1804, 0.8314,\n",
              "         0.7647, 0.8314, 0.7922, 0.8078, 0.8039, 0.8000, 0.8039, 0.8078, 0.8000,\n",
              "         0.8314, 0.7843, 0.8549, 0.3569, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0431, 0.7725,\n",
              "         0.7804, 0.8039, 0.7922, 0.8039, 0.8078, 0.8000, 0.8039, 0.8118, 0.8000,\n",
              "         0.8039, 0.8039, 0.8549, 0.3020, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0078, 0.7490,\n",
              "         0.7765, 0.7882, 0.8039, 0.8078, 0.8039, 0.8039, 0.8078, 0.8196, 0.8078,\n",
              "         0.7804, 0.8196, 0.8588, 0.2902, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.7373,\n",
              "         0.7725, 0.7843, 0.8118, 0.8118, 0.8000, 0.8118, 0.8118, 0.8235, 0.8157,\n",
              "         0.7765, 0.8118, 0.8667, 0.2824, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8431,\n",
              "         0.7765, 0.7961, 0.8078, 0.8157, 0.8039, 0.8118, 0.8118, 0.8235, 0.8157,\n",
              "         0.7843, 0.7922, 0.8706, 0.2941, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8314,\n",
              "         0.7765, 0.8196, 0.8078, 0.8196, 0.8078, 0.8157, 0.8118, 0.8275, 0.8078,\n",
              "         0.8039, 0.7765, 0.8667, 0.3137, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8000,\n",
              "         0.7882, 0.8039, 0.8157, 0.8118, 0.8039, 0.8275, 0.8039, 0.8235, 0.8235,\n",
              "         0.8196, 0.7647, 0.8667, 0.3765, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7922,\n",
              "         0.7882, 0.8039, 0.8196, 0.8118, 0.8039, 0.8353, 0.8078, 0.8235, 0.8196,\n",
              "         0.8235, 0.7608, 0.8510, 0.4118, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8000,\n",
              "         0.8000, 0.8039, 0.8157, 0.8118, 0.8039, 0.8431, 0.8118, 0.8235, 0.8157,\n",
              "         0.8275, 0.7569, 0.8353, 0.4510, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n",
              "         0.8118, 0.8118, 0.8157, 0.8078, 0.8078, 0.8431, 0.8235, 0.8235, 0.8118,\n",
              "         0.8314, 0.7647, 0.8235, 0.4627, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7765,\n",
              "         0.8157, 0.8157, 0.8157, 0.8000, 0.8118, 0.8314, 0.8314, 0.8235, 0.8118,\n",
              "         0.8275, 0.7686, 0.8118, 0.4745, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7765,\n",
              "         0.8235, 0.8118, 0.8157, 0.8078, 0.8196, 0.8353, 0.8314, 0.8275, 0.8118,\n",
              "         0.8235, 0.7725, 0.8118, 0.4863, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745,\n",
              "         0.8235, 0.7961, 0.7882, 0.7804, 0.8000, 0.8118, 0.8039, 0.8000, 0.7882,\n",
              "         0.8039, 0.7725, 0.8078, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373,\n",
              "         0.8667, 0.8392, 0.9176, 0.9255, 0.9333, 0.9569, 0.9569, 0.9569, 0.9412,\n",
              "         0.9529, 0.8392, 0.8784, 0.6353, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.5451,\n",
              "         0.5725, 0.5098, 0.5294, 0.5294, 0.5373, 0.4902, 0.4863, 0.4902, 0.4745,\n",
              "         0.4667, 0.4471, 0.5098, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orhS4OKbbxb0"
      },
      "source": [
        "# Creating Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aun1NS_Hb1R9"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            #Layer 1 - 64 Nodes\n",
        "            #Layer 2 - 128 Nodes\n",
        "            #Relu Activation for each layer\n",
        "            nn.Linear(28*28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64 , 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "#Can also declare the layers as linear layer 1 etc..\n",
        "#defining forward function that passes the data on each epoch\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY_U_qwmdxwK"
      },
      "source": [
        "Checking for the devices we have so that we can run the code either on GPU or on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm4teak5dscY",
        "outputId": "54385896-c546-464a-df24-99f85aa8ca41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2VioxzZb8cR",
        "outputId": "041f42d7-7934-4c35-90b8-2ca98ccdaaa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkl7NW2uMVUd"
      },
      "source": [
        "Here we see how the initialisations are done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVfZp4GYHjyP",
        "outputId": "c2130702-fa25-44e6-df0d-388c3a23d680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------\n",
            "('0.weight', Parameter containing:\n",
            "tensor([[-0.0348,  0.0212, -0.0083,  ..., -0.0318,  0.0341, -0.0325],\n",
            "        [ 0.0041,  0.0069,  0.0315,  ..., -0.0077, -0.0034, -0.0324],\n",
            "        [ 0.0046,  0.0129,  0.0199,  ..., -0.0213, -0.0246,  0.0052],\n",
            "        ...,\n",
            "        [ 0.0164, -0.0111,  0.0138,  ..., -0.0267,  0.0115, -0.0177],\n",
            "        [-0.0060,  0.0240,  0.0170,  ...,  0.0295, -0.0255,  0.0010],\n",
            "        [-0.0289, -0.0282,  0.0284,  ...,  0.0344, -0.0253, -0.0308]],\n",
            "       requires_grad=True))\n",
            "torch.Size([64, 784])\n",
            "---------------------------------------------------------------------------------------\n",
            "('0.bias', Parameter containing:\n",
            "tensor([ 0.0308,  0.0240,  0.0290,  0.0316, -0.0285,  0.0138, -0.0069, -0.0196,\n",
            "         0.0121,  0.0270, -0.0013,  0.0151, -0.0075, -0.0267,  0.0143, -0.0324,\n",
            "         0.0228,  0.0352,  0.0038,  0.0130,  0.0234, -0.0347, -0.0151,  0.0246,\n",
            "         0.0091, -0.0286,  0.0048, -0.0024, -0.0146,  0.0120,  0.0270,  0.0153,\n",
            "         0.0077,  0.0148, -0.0073,  0.0338, -0.0236,  0.0351,  0.0068, -0.0295,\n",
            "        -0.0001, -0.0186,  0.0132, -0.0219,  0.0038,  0.0100, -0.0131, -0.0245,\n",
            "        -0.0013,  0.0029,  0.0193, -0.0143,  0.0223,  0.0193,  0.0058, -0.0227,\n",
            "         0.0319,  0.0067, -0.0229, -0.0143,  0.0191, -0.0131,  0.0046,  0.0267],\n",
            "       requires_grad=True))\n",
            "torch.Size([64])\n",
            "---------------------------------------------------------------------------------------\n",
            "('2.weight', Parameter containing:\n",
            "tensor([[-0.0865, -0.0282,  0.0746,  ..., -0.0905,  0.0634, -0.1153],\n",
            "        [-0.1184, -0.0423, -0.0163,  ...,  0.1068,  0.0298,  0.0524],\n",
            "        [-0.0170, -0.1140, -0.1080,  ...,  0.0881,  0.0124,  0.0993],\n",
            "        ...,\n",
            "        [ 0.0500, -0.0979,  0.0485,  ..., -0.1103, -0.0607, -0.0558],\n",
            "        [ 0.0742, -0.0796,  0.0221,  ..., -0.0080,  0.0940, -0.0163],\n",
            "        [-0.0635, -0.1218, -0.1117,  ..., -0.0999,  0.0647,  0.0244]],\n",
            "       requires_grad=True))\n",
            "torch.Size([128, 64])\n",
            "---------------------------------------------------------------------------------------\n",
            "('2.bias', Parameter containing:\n",
            "tensor([-0.0655,  0.1052, -0.0957, -0.0220,  0.0982,  0.0165, -0.0712, -0.0562,\n",
            "        -0.1175,  0.1081, -0.1037, -0.0044,  0.0724, -0.1005, -0.0271, -0.0125,\n",
            "        -0.0168,  0.1225, -0.0014,  0.0180,  0.0049, -0.0454,  0.0875, -0.0409,\n",
            "        -0.0102,  0.0947, -0.0891,  0.0668, -0.0400, -0.0721, -0.0408,  0.0589,\n",
            "        -0.0239,  0.0274,  0.0277,  0.0363,  0.0466,  0.0345, -0.1110,  0.0349,\n",
            "         0.0659,  0.1012,  0.0628,  0.0951,  0.0475,  0.1149, -0.0829, -0.0750,\n",
            "        -0.0191,  0.0052,  0.0553, -0.0521,  0.0558, -0.0205,  0.0913,  0.0618,\n",
            "         0.0108, -0.0281, -0.0073,  0.0721, -0.0716, -0.0997,  0.1200,  0.1231,\n",
            "         0.0228,  0.1196,  0.1202,  0.1063,  0.0915, -0.0131,  0.1176,  0.1205,\n",
            "         0.0926, -0.0939,  0.1169,  0.0335,  0.0256, -0.0111,  0.0567, -0.0657,\n",
            "        -0.0206,  0.0635,  0.1188,  0.0500, -0.1117,  0.0728, -0.0668, -0.0361,\n",
            "         0.0508, -0.0357,  0.0185,  0.0037,  0.0477,  0.0008,  0.0786, -0.0192,\n",
            "        -0.1235, -0.0602, -0.1138, -0.0356, -0.0416,  0.0242,  0.0473,  0.0978,\n",
            "         0.0854,  0.0444, -0.0728,  0.1030, -0.0545,  0.0739, -0.0863,  0.1192,\n",
            "         0.0894,  0.0840,  0.0480, -0.0121,  0.0436,  0.0490, -0.0108, -0.0752,\n",
            "        -0.0215, -0.0687, -0.0027,  0.0497, -0.0656,  0.0464,  0.0237,  0.0382],\n",
            "       requires_grad=True))\n",
            "torch.Size([128])\n",
            "---------------------------------------------------------------------------------------\n",
            "('4.weight', Parameter containing:\n",
            "tensor([[ 0.0428,  0.0454, -0.0719,  ...,  0.0241, -0.0463, -0.0214],\n",
            "        [ 0.0282,  0.0227,  0.0190,  ..., -0.0564, -0.0870,  0.0330],\n",
            "        [ 0.0599, -0.0075,  0.0348,  ...,  0.0192, -0.0621, -0.0628],\n",
            "        ...,\n",
            "        [ 0.0416, -0.0711, -0.0103,  ..., -0.0069, -0.0431, -0.0393],\n",
            "        [-0.0489,  0.0376, -0.0438,  ..., -0.0597,  0.0595, -0.0493],\n",
            "        [-0.0833,  0.0063,  0.0225,  ..., -0.0322,  0.0765, -0.0296]],\n",
            "       requires_grad=True))\n",
            "torch.Size([10, 128])\n",
            "---------------------------------------------------------------------------------------\n",
            "('4.bias', Parameter containing:\n",
            "tensor([ 0.0801, -0.0744, -0.0679, -0.0340,  0.0042, -0.0337,  0.0349, -0.0489,\n",
            "        -0.0394, -0.0451], requires_grad=True))\n",
            "torch.Size([10])\n",
            "---------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\"for params in model.parameters() :\n",
        "  print(params)\"\"\"\n",
        "print(\"---------------------------------------------------------------------------------------\")\n",
        "for linParams in model.linear_relu_stack.named_parameters():\n",
        "  print(linParams)\n",
        "  print(linParams[1].size())\n",
        "  print(\"---------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnLqwdxqCmm"
      },
      "source": [
        "Hyper Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr9MIpmaD-NT"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pAoa6DOD8k6"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader,model,lossFn,optimizer1) :\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  # Set the model to training mode\n",
        "  model.train()\n",
        "\n",
        "  for batch,(X,y) in enumerate(dataloader) :\n",
        "\n",
        "    #Predictions and loss as we call forward and loss is calculated to be further used\n",
        "    pred = model(X)\n",
        "    #make_dot(pred, params=dict(model.named_parameters()))\n",
        "    loss = lossFn(pred,y)\n",
        "\n",
        "    #Backpropagation\n",
        "    #Calculation of Gradient\n",
        "    loss.backward()\n",
        "    #This would update the weights and biases\n",
        "    optimizer1.step()\n",
        "    #This would zero down the gradients so that they arent added up in next step\n",
        "    optimizer1.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u__E7Qo_U4YS"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    #Set model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    #Mean or average of loss\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return 100*correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COETMezjeWOL"
      },
      "outputs": [],
      "source": [
        "learningRate = 1e-1\n",
        "batchSize  = 128\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpRbqE71lXBl"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=batchSize,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batchSize,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6WB1SJ0h2eH"
      },
      "outputs": [],
      "source": [
        "#Combines LogSoftmax and NLLLoss - Negativce log likelihood\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "optimizer1 = torch.optim.SGD(model.parameters(),lr = learningRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtPnVfzsVubJ",
        "outputId": "385c7ec5-b166-4dfe-de17-f2698c0ed758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.347870  [  128/60000]\n",
            "loss: 0.346941  [12928/60000]\n",
            "loss: 0.309573  [25728/60000]\n",
            "loss: 0.202681  [38528/60000]\n",
            "loss: 0.216991  [51328/60000]\n",
            "Train Error : \tAccuracy: 91.4%, Avg loss: 0.231657 \n",
            "\n",
            "Test Error : \tAccuracy: 88.1%, Avg loss: 0.344753 \n",
            "\n",
            "Decent\n",
            "\n",
            "Model saved with accuracy: 88.08%\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.231969  [  128/60000]\n",
            "loss: 0.239366  [12928/60000]\n",
            "loss: 0.194790  [25728/60000]\n",
            "loss: 0.274128  [38528/60000]\n",
            "loss: 0.182898  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.1%, Avg loss: 0.217026 \n",
            "\n",
            "Test Error : \tAccuracy: 88.5%, Avg loss: 0.340185 \n",
            "\n",
            "Decent\n",
            "\n",
            "Model saved with accuracy: 88.50%\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.150159  [  128/60000]\n",
            "loss: 0.280020  [12928/60000]\n",
            "loss: 0.211407  [25728/60000]\n",
            "loss: 0.240553  [38528/60000]\n",
            "loss: 0.280897  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.4%, Avg loss: 0.205998 \n",
            "\n",
            "Test Error : \tAccuracy: 88.7%, Avg loss: 0.324597 \n",
            "\n",
            "Decent\n",
            "\n",
            "Model saved with accuracy: 88.69%\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.169547  [  128/60000]\n",
            "loss: 0.131594  [12928/60000]\n",
            "loss: 0.246472  [25728/60000]\n",
            "loss: 0.225870  [38528/60000]\n",
            "loss: 0.254500  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.2%, Avg loss: 0.211517 \n",
            "\n",
            "Test Error : \tAccuracy: 88.6%, Avg loss: 0.332812 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.199069  [  128/60000]\n",
            "loss: 0.136735  [12928/60000]\n",
            "loss: 0.311794  [25728/60000]\n",
            "loss: 0.292374  [38528/60000]\n",
            "loss: 0.285567  [51328/60000]\n",
            "Train Error : \tAccuracy: 91.9%, Avg loss: 0.215295 \n",
            "\n",
            "Test Error : \tAccuracy: 88.3%, Avg loss: 0.336666 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.245914  [  128/60000]\n",
            "loss: 0.225413  [12928/60000]\n",
            "loss: 0.235208  [25728/60000]\n",
            "loss: 0.286040  [38528/60000]\n",
            "loss: 0.214166  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.7%, Avg loss: 0.199660 \n",
            "\n",
            "Test Error : \tAccuracy: 88.6%, Avg loss: 0.325950 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.266288  [  128/60000]\n",
            "loss: 0.171393  [12928/60000]\n",
            "loss: 0.293562  [25728/60000]\n",
            "loss: 0.261773  [38528/60000]\n",
            "loss: 0.253413  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.0%, Avg loss: 0.195742 \n",
            "\n",
            "Test Error : \tAccuracy: 88.9%, Avg loss: 0.318337 \n",
            "\n",
            "Decent\n",
            "\n",
            "Model saved with accuracy: 88.90%\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.254577  [  128/60000]\n",
            "loss: 0.168997  [12928/60000]\n",
            "loss: 0.323978  [25728/60000]\n",
            "loss: 0.272642  [38528/60000]\n",
            "loss: 0.301784  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.4%, Avg loss: 0.205246 \n",
            "\n",
            "Test Error : \tAccuracy: 88.2%, Avg loss: 0.339805 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.243763  [  128/60000]\n",
            "loss: 0.193300  [12928/60000]\n",
            "loss: 0.186249  [25728/60000]\n",
            "loss: 0.254877  [38528/60000]\n",
            "loss: 0.240236  [51328/60000]\n",
            "Train Error : \tAccuracy: 91.6%, Avg loss: 0.224798 \n",
            "\n",
            "Test Error : \tAccuracy: 87.7%, Avg loss: 0.359890 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.230959  [  128/60000]\n",
            "loss: 0.212304  [12928/60000]\n",
            "loss: 0.241889  [25728/60000]\n",
            "loss: 0.160051  [38528/60000]\n",
            "loss: 0.240067  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.2%, Avg loss: 0.205815 \n",
            "\n",
            "Test Error : \tAccuracy: 88.0%, Avg loss: 0.339153 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.184269  [  128/60000]\n",
            "loss: 0.253318  [12928/60000]\n",
            "loss: 0.195299  [25728/60000]\n",
            "loss: 0.122022  [38528/60000]\n",
            "loss: 0.218756  [51328/60000]\n",
            "Train Error : \tAccuracy: 91.5%, Avg loss: 0.219001 \n",
            "\n",
            "Test Error : \tAccuracy: 87.2%, Avg loss: 0.360441 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.208994  [  128/60000]\n",
            "loss: 0.179751  [12928/60000]\n",
            "loss: 0.128886  [25728/60000]\n",
            "loss: 0.156777  [38528/60000]\n",
            "loss: 0.226668  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.7%, Avg loss: 0.199101 \n",
            "\n",
            "Test Error : \tAccuracy: 88.4%, Avg loss: 0.348132 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.215114  [  128/60000]\n",
            "loss: 0.194444  [12928/60000]\n",
            "loss: 0.193281  [25728/60000]\n",
            "loss: 0.214232  [38528/60000]\n",
            "loss: 0.269635  [51328/60000]\n",
            "Train Error : \tAccuracy: 91.0%, Avg loss: 0.237978 \n",
            "\n",
            "Test Error : \tAccuracy: 87.0%, Avg loss: 0.389716 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.215572  [  128/60000]\n",
            "loss: 0.143783  [12928/60000]\n",
            "loss: 0.280132  [25728/60000]\n",
            "loss: 0.180908  [38528/60000]\n",
            "loss: 0.091393  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.1%, Avg loss: 0.210428 \n",
            "\n",
            "Test Error : \tAccuracy: 87.8%, Avg loss: 0.366247 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.219517  [  128/60000]\n",
            "loss: 0.156585  [12928/60000]\n",
            "loss: 0.138586  [25728/60000]\n",
            "loss: 0.157256  [38528/60000]\n",
            "loss: 0.161942  [51328/60000]\n",
            "Train Error : \tAccuracy: 92.5%, Avg loss: 0.200355 \n",
            "\n",
            "Test Error : \tAccuracy: 87.7%, Avg loss: 0.355694 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.197761  [  128/60000]\n",
            "loss: 0.184912  [12928/60000]\n",
            "loss: 0.131837  [25728/60000]\n",
            "loss: 0.196706  [38528/60000]\n",
            "loss: 0.232147  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.2%, Avg loss: 0.184566 \n",
            "\n",
            "Test Error : \tAccuracy: 88.6%, Avg loss: 0.342079 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.134960  [  128/60000]\n",
            "loss: 0.187223  [12928/60000]\n",
            "loss: 0.237431  [25728/60000]\n",
            "loss: 0.251814  [38528/60000]\n",
            "loss: 0.219017  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.5%, Avg loss: 0.174573 \n",
            "\n",
            "Test Error : \tAccuracy: 88.9%, Avg loss: 0.337630 \n",
            "\n",
            "Decent\n",
            "\n",
            "Model saved with accuracy: 88.94%\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.289164  [  128/60000]\n",
            "loss: 0.255297  [12928/60000]\n",
            "loss: 0.178504  [25728/60000]\n",
            "loss: 0.162338  [38528/60000]\n",
            "loss: 0.258786  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.7%, Avg loss: 0.170965 \n",
            "\n",
            "Test Error : \tAccuracy: 88.8%, Avg loss: 0.339828 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.184627  [  128/60000]\n",
            "loss: 0.198126  [12928/60000]\n",
            "loss: 0.164558  [25728/60000]\n",
            "loss: 0.138535  [38528/60000]\n",
            "loss: 0.232793  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.2%, Avg loss: 0.181027 \n",
            "\n",
            "Test Error : \tAccuracy: 88.5%, Avg loss: 0.356032 \n",
            "\n",
            "Decent\n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.130248  [  128/60000]\n",
            "loss: 0.130174  [12928/60000]\n",
            "loss: 0.186688  [25728/60000]\n",
            "loss: 0.205321  [38528/60000]\n",
            "loss: 0.134322  [51328/60000]\n",
            "Train Error : \tAccuracy: 93.8%, Avg loss: 0.168071 \n",
            "\n",
            "Test Error : \tAccuracy: 88.6%, Avg loss: 0.340218 \n",
            "\n",
            "Low bias , High Variance\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "maxAccuracy = 0.0\n",
        "modelPath = \"/content/drive/MyDrive/Colab Notebooks/MTCS-205/Assignments/Assignment-1-Model/maxAccuracyModel.pth\"\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    #Training phase here where we check for bias of the model\n",
        "    train_loop(train_dataloader, model, lossFn, optimizer1)\n",
        "    print(\"Train Error : \",end = '\\t')\n",
        "    trainAccuracy = test_loop(train_dataloader, model, lossFn)\n",
        "\n",
        "    #test_loop(test_dataloader, model, lossFn)\n",
        "    print(\"Test Error : \",end = '\\t')\n",
        "    testAccuracy = test_loop(test_dataloader, model, lossFn)\n",
        "\n",
        "    if (trainAccuracy > testAccuracy) and (trainAccuracy-testAccuracy) > 5 :\n",
        "      print(\"Low bias , High Variance\\n\")\n",
        "    else :\n",
        "      print(\"Decent\\n\")\n",
        "\n",
        "    if testAccuracy > maxAccuracy :\n",
        "      maxAccuracy = testAccuracy\n",
        "      torch.save(model.state_dict(), modelPath)\n",
        "      print(f\"Model saved with accuracy: {maxAccuracy:.2f}%\")\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisations in Tensorboard"
      ],
      "metadata": {
        "id": "3AF_Hx4r-Gw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnGGD1FMvnl9"
      },
      "outputs": [],
      "source": [
        "\"\"\"logsPath = \"/content/drive/MyDrive/Colab Notebooks/MTCS-205/Assignments/logs\"\n",
        "writer = SummaryWriter(logsPath)\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ujvSXRfnvVZcmyvZZS0Ekyg_2cDDGWg7",
      "authorship_tag": "ABX9TyMuUZvpm3167axvPKQp+NwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}