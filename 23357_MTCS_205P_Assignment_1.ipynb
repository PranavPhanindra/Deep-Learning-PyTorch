{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavPhanindra/Deep-Learning-PyTorch/blob/main/23357_MTCS_205P_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P8WcNwtbgfM"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci4sQkUSOZdO",
        "outputId": "b98dc6f4-b95e-4d84-956e-d6cd1cfa7ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=3d08e8c22cac15c8d888ca6ed174c4ed2f7726f1aeff5280247b24194931c456\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz\n",
        "!pip install tensorboard\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G7gdBlqfv_-p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "\n",
        "from pyngrok import ngrok\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchviz import make_dot\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gsygWWJebsq"
      },
      "source": [
        "# Data Loading and info about Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KtS5JpmwegFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da19e59-c303-473e-8829-35650669c090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:13<00:00, 2021076.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 317855.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5581929.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 13657354.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6QZxzgnViBA0"
      },
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "#Defining labels for different classes of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "O3t2B97Se-1i",
        "outputId": "36c57848-0356-4bce-a09b-e0d826176db0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "img,label = training_data[1]\n",
        "img = img.reshape(28,28)\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.title(labels_map[label])\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQmu2EJmy3H3",
        "outputId": "3bcbff79-5f2d-47b6-ab2f-fec6d472faba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1608, 0.7373, 0.4039, 0.2118, 0.1882, 0.1686, 0.3412, 0.6588,\n",
              "         0.5216, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.1922, 0.5333,\n",
              "         0.8588, 0.8471, 0.8941, 0.9255, 1.0000, 1.0000, 1.0000, 1.0000, 0.8510,\n",
              "         0.8431, 0.9961, 0.9059, 0.6275, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6902, 0.8706, 0.8784,\n",
              "         0.8314, 0.7961, 0.7765, 0.7686, 0.7843, 0.8431, 0.8000, 0.7922, 0.7882,\n",
              "         0.7882, 0.7882, 0.8196, 0.8549, 0.8784, 0.6431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.8588, 0.7843, 0.7765,\n",
              "         0.7922, 0.7765, 0.7804, 0.7804, 0.7882, 0.7686, 0.7765, 0.7765, 0.7843,\n",
              "         0.7843, 0.7843, 0.7843, 0.7882, 0.7843, 0.8824, 0.1608, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.8588, 0.7804, 0.7961, 0.7961,\n",
              "         0.8314, 0.9333, 0.9725, 0.9804, 0.9608, 0.9765, 0.9647, 0.9686, 0.9882,\n",
              "         0.9725, 0.9216, 0.8118, 0.7961, 0.7961, 0.8706, 0.5490, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.8863, 0.8078, 0.8000, 0.8118,\n",
              "         0.8000, 0.3961, 0.2941, 0.1843, 0.2863, 0.1882, 0.1961, 0.1765, 0.2000,\n",
              "         0.2471, 0.4431, 0.8706, 0.7922, 0.8078, 0.8627, 0.8784, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8706, 0.8196, 0.7961, 0.8431,\n",
              "         0.7843, 0.0000, 0.2745, 0.3843, 0.0000, 0.4039, 0.2314, 0.2667, 0.2784,\n",
              "         0.1922, 0.0000, 0.8588, 0.8078, 0.8392, 0.8235, 0.9804, 0.1490, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9686, 0.8549, 0.8314, 0.8235, 0.8431,\n",
              "         0.8392, 0.0000, 0.9961, 0.9529, 0.5451, 1.0000, 0.6824, 0.9843, 1.0000,\n",
              "         0.8039, 0.0000, 0.8431, 0.8510, 0.8392, 0.8157, 0.8627, 0.3725, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.1765, 0.8863, 0.8392, 0.8392, 0.8431, 0.8784,\n",
              "         0.8039, 0.0000, 0.1647, 0.1373, 0.2353, 0.0627, 0.0667, 0.0471, 0.0510,\n",
              "         0.2745, 0.0000, 0.7412, 0.8471, 0.8314, 0.8078, 0.8314, 0.6118, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.6431, 0.9216, 0.8392, 0.8275, 0.8627, 0.8471,\n",
              "         0.7882, 0.2039, 0.2784, 0.3490, 0.3686, 0.3255, 0.3059, 0.2745, 0.2980,\n",
              "         0.3608, 0.3412, 0.8078, 0.8118, 0.8706, 0.8353, 0.8588, 0.8157, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.4157, 0.7333, 0.8745, 0.9294, 0.9725, 0.8275,\n",
              "         0.7765, 0.9882, 0.9804, 0.9725, 0.9608, 0.9725, 0.9882, 0.9922, 0.9804,\n",
              "         0.9882, 0.9373, 0.7882, 0.8314, 0.8824, 0.8431, 0.7569, 0.4431, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2118, 0.6235, 0.8706,\n",
              "         0.7569, 0.8157, 0.7529, 0.7725, 0.7843, 0.7843, 0.7843, 0.7843, 0.7882,\n",
              "         0.7961, 0.7647, 0.8235, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.8824,\n",
              "         0.7529, 0.8392, 0.7961, 0.8078, 0.8000, 0.8000, 0.8039, 0.8078, 0.8000,\n",
              "         0.8314, 0.7725, 0.8549, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0235, 0.0000, 0.1804, 0.8314,\n",
              "         0.7647, 0.8314, 0.7922, 0.8078, 0.8039, 0.8000, 0.8039, 0.8078, 0.8000,\n",
              "         0.8314, 0.7843, 0.8549, 0.3569, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0431, 0.7725,\n",
              "         0.7804, 0.8039, 0.7922, 0.8039, 0.8078, 0.8000, 0.8039, 0.8118, 0.8000,\n",
              "         0.8039, 0.8039, 0.8549, 0.3020, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0078, 0.7490,\n",
              "         0.7765, 0.7882, 0.8039, 0.8078, 0.8039, 0.8039, 0.8078, 0.8196, 0.8078,\n",
              "         0.7804, 0.8196, 0.8588, 0.2902, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.7373,\n",
              "         0.7725, 0.7843, 0.8118, 0.8118, 0.8000, 0.8118, 0.8118, 0.8235, 0.8157,\n",
              "         0.7765, 0.8118, 0.8667, 0.2824, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8431,\n",
              "         0.7765, 0.7961, 0.8078, 0.8157, 0.8039, 0.8118, 0.8118, 0.8235, 0.8157,\n",
              "         0.7843, 0.7922, 0.8706, 0.2941, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8314,\n",
              "         0.7765, 0.8196, 0.8078, 0.8196, 0.8078, 0.8157, 0.8118, 0.8275, 0.8078,\n",
              "         0.8039, 0.7765, 0.8667, 0.3137, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8000,\n",
              "         0.7882, 0.8039, 0.8157, 0.8118, 0.8039, 0.8275, 0.8039, 0.8235, 0.8235,\n",
              "         0.8196, 0.7647, 0.8667, 0.3765, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7922,\n",
              "         0.7882, 0.8039, 0.8196, 0.8118, 0.8039, 0.8353, 0.8078, 0.8235, 0.8196,\n",
              "         0.8235, 0.7608, 0.8510, 0.4118, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8000,\n",
              "         0.8000, 0.8039, 0.8157, 0.8118, 0.8039, 0.8431, 0.8118, 0.8235, 0.8157,\n",
              "         0.8275, 0.7569, 0.8353, 0.4510, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n",
              "         0.8118, 0.8118, 0.8157, 0.8078, 0.8078, 0.8431, 0.8235, 0.8235, 0.8118,\n",
              "         0.8314, 0.7647, 0.8235, 0.4627, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7765,\n",
              "         0.8157, 0.8157, 0.8157, 0.8000, 0.8118, 0.8314, 0.8314, 0.8235, 0.8118,\n",
              "         0.8275, 0.7686, 0.8118, 0.4745, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.7765,\n",
              "         0.8235, 0.8118, 0.8157, 0.8078, 0.8196, 0.8353, 0.8314, 0.8275, 0.8118,\n",
              "         0.8235, 0.7725, 0.8118, 0.4863, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745,\n",
              "         0.8235, 0.7961, 0.7882, 0.7804, 0.8000, 0.8118, 0.8039, 0.8000, 0.7882,\n",
              "         0.8039, 0.7725, 0.8078, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373,\n",
              "         0.8667, 0.8392, 0.9176, 0.9255, 0.9333, 0.9569, 0.9569, 0.9569, 0.9412,\n",
              "         0.9529, 0.8392, 0.8784, 0.6353, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.5451,\n",
              "         0.5725, 0.5098, 0.5294, 0.5294, 0.5373, 0.4902, 0.4863, 0.4902, 0.4745,\n",
              "         0.4667, 0.4471, 0.5098, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orhS4OKbbxb0"
      },
      "source": [
        "# Creating Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Aun1NS_Hb1R9"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            #Layer 1 - 64 Nodes\n",
        "            #Layer 2 - 128 Nodes\n",
        "            #Relu Activation for each layer\n",
        "            nn.Linear(28*28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64 , 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "#Can also declare the layers as linear layer 1 etc..\n",
        "#defining forward function that passes the data on each epoch\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY_U_qwmdxwK"
      },
      "source": [
        "Checking for the devices we have so that we can run the code either on GPU or on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm4teak5dscY",
        "outputId": "0ec7ac3b-c2a7-4254-d199-8c0886e6b614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2VioxzZb8cR",
        "outputId": "5b7f6d8a-c9a7-4fef-dbe0-de1c516349c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkl7NW2uMVUd"
      },
      "source": [
        "Here we see how the initialisations are done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVfZp4GYHjyP",
        "outputId": "e83446c7-cd30-4d87-b13a-1acf1929d773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------\n",
            "('0.weight', Parameter containing:\n",
            "tensor([[ 0.0206, -0.0163, -0.0011,  ...,  0.0258,  0.0267,  0.0046],\n",
            "        [-0.0255,  0.0253, -0.0327,  ..., -0.0347,  0.0035,  0.0335],\n",
            "        [-0.0249,  0.0063, -0.0182,  ..., -0.0180, -0.0250, -0.0182],\n",
            "        ...,\n",
            "        [ 0.0310, -0.0254, -0.0315,  ..., -0.0133, -0.0119,  0.0182],\n",
            "        [ 0.0208, -0.0012,  0.0195,  ...,  0.0210, -0.0336,  0.0078],\n",
            "        [-0.0152,  0.0053,  0.0252,  ..., -0.0354, -0.0230, -0.0138]],\n",
            "       requires_grad=True))\n",
            "torch.Size([64, 784])\n",
            "---------------------------------------------------------------------------------------\n",
            "('0.bias', Parameter containing:\n",
            "tensor([ 0.0240,  0.0296,  0.0277,  0.0114, -0.0030, -0.0114, -0.0011,  0.0192,\n",
            "        -0.0353,  0.0254,  0.0174, -0.0239, -0.0140,  0.0212, -0.0289, -0.0159,\n",
            "         0.0100, -0.0333, -0.0067,  0.0071,  0.0048, -0.0108,  0.0156, -0.0244,\n",
            "        -0.0197,  0.0206, -0.0140,  0.0085, -0.0328,  0.0323, -0.0142,  0.0055,\n",
            "        -0.0305, -0.0159, -0.0289, -0.0215, -0.0182,  0.0304,  0.0218, -0.0013,\n",
            "        -0.0309, -0.0145,  0.0339,  0.0007, -0.0033, -0.0303, -0.0205,  0.0008,\n",
            "         0.0081, -0.0042,  0.0071, -0.0081,  0.0198, -0.0191,  0.0290, -0.0149,\n",
            "        -0.0334,  0.0054,  0.0285, -0.0066,  0.0127, -0.0217, -0.0031,  0.0139],\n",
            "       requires_grad=True))\n",
            "torch.Size([64])\n",
            "---------------------------------------------------------------------------------------\n",
            "('2.weight', Parameter containing:\n",
            "tensor([[-0.0628,  0.0457, -0.0100,  ..., -0.0179, -0.0676,  0.0296],\n",
            "        [-0.0171, -0.0880,  0.0260,  ...,  0.0298, -0.1179,  0.0730],\n",
            "        [-0.1182,  0.0640, -0.0113,  ...,  0.0965,  0.0533, -0.0473],\n",
            "        ...,\n",
            "        [-0.0841, -0.0787,  0.0274,  ..., -0.0350, -0.0264, -0.0004],\n",
            "        [-0.0213, -0.1204, -0.0819,  ...,  0.0674, -0.1229,  0.0408],\n",
            "        [ 0.0889,  0.0953,  0.1002,  ...,  0.0594,  0.1132,  0.0628]],\n",
            "       requires_grad=True))\n",
            "torch.Size([128, 64])\n",
            "---------------------------------------------------------------------------------------\n",
            "('2.bias', Parameter containing:\n",
            "tensor([-0.0514, -0.0025, -0.1054, -0.0988, -0.0546, -0.1247, -0.0764, -0.0563,\n",
            "         0.0748,  0.0438,  0.0506, -0.0389,  0.0669, -0.0040,  0.0669,  0.0901,\n",
            "        -0.0121,  0.0404, -0.0129, -0.0370, -0.0965, -0.1082,  0.0736,  0.0443,\n",
            "        -0.0219,  0.0117, -0.1149,  0.0024, -0.0252, -0.1172, -0.1148,  0.0956,\n",
            "         0.0339, -0.0526,  0.0107,  0.0944, -0.0752,  0.1018,  0.0225, -0.0480,\n",
            "        -0.1192, -0.0129,  0.0113, -0.0530, -0.0498,  0.0068,  0.0704,  0.0868,\n",
            "         0.1064, -0.0402,  0.1005, -0.1027, -0.0340,  0.0990,  0.0104,  0.0820,\n",
            "         0.0465,  0.0119, -0.0519, -0.0276, -0.0421, -0.0408,  0.0843,  0.1156,\n",
            "         0.1234, -0.0519,  0.0960,  0.0473, -0.1189, -0.0213,  0.1139, -0.1087,\n",
            "        -0.1211, -0.0417,  0.0444,  0.0872,  0.0313,  0.0548, -0.0458, -0.1167,\n",
            "        -0.0698, -0.0368,  0.0730,  0.0007,  0.0763, -0.0508, -0.0061, -0.0186,\n",
            "         0.0535,  0.0766, -0.0912,  0.0443,  0.0143, -0.0259, -0.0429, -0.0465,\n",
            "        -0.0470, -0.0174, -0.0792,  0.0935, -0.0243,  0.1228, -0.0188,  0.1130,\n",
            "         0.0102,  0.1214,  0.1090,  0.0195, -0.0773, -0.0005, -0.0683,  0.0708,\n",
            "         0.0253, -0.0727, -0.1212, -0.0413,  0.1195,  0.0895, -0.0879, -0.1216,\n",
            "         0.0242, -0.0243,  0.1236,  0.0940,  0.0269,  0.1112, -0.0419, -0.0538],\n",
            "       requires_grad=True))\n",
            "torch.Size([128])\n",
            "---------------------------------------------------------------------------------------\n",
            "('4.weight', Parameter containing:\n",
            "tensor([[ 0.0029,  0.0327, -0.0544,  ..., -0.0219, -0.0665,  0.0197],\n",
            "        [ 0.0368, -0.0004,  0.0289,  ...,  0.0764,  0.0583, -0.0879],\n",
            "        [-0.0844,  0.0203,  0.0215,  ..., -0.0334,  0.0564, -0.0861],\n",
            "        ...,\n",
            "        [-0.0860, -0.0132, -0.0150,  ...,  0.0074, -0.0347,  0.0606],\n",
            "        [ 0.0350,  0.0217, -0.0276,  ...,  0.0044,  0.0299,  0.0677],\n",
            "        [-0.0324,  0.0573,  0.0856,  ..., -0.0243,  0.0128,  0.0082]],\n",
            "       requires_grad=True))\n",
            "torch.Size([10, 128])\n",
            "---------------------------------------------------------------------------------------\n",
            "('4.bias', Parameter containing:\n",
            "tensor([ 0.0591, -0.0132,  0.0763, -0.0481,  0.0817, -0.0573, -0.0323, -0.0726,\n",
            "         0.0745, -0.0556], requires_grad=True))\n",
            "torch.Size([10])\n",
            "---------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\"for params in model.parameters() :\n",
        "  print(params)\"\"\"\n",
        "print(\"---------------------------------------------------------------------------------------\")\n",
        "for linParams in model.linear_relu_stack.named_parameters():\n",
        "  print(linParams)\n",
        "  print(linParams[1].size())\n",
        "  print(\"---------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnLqwdxqCmm"
      },
      "source": [
        "Hyper Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr9MIpmaD-NT"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0pAoa6DOD8k6"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader,model,lossFn,optimizer1) :\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  # Set the model to training mode\n",
        "  model.train()\n",
        "\n",
        "  for batch,(X,y) in enumerate(dataloader) :\n",
        "\n",
        "    #Predictions and loss as we call forward and loss is calculated to be further used\n",
        "    pred = model(X)\n",
        "    #make_dot(pred, params=dict(model.named_parameters()))\n",
        "    loss = lossFn(pred,y)\n",
        "\n",
        "    #Backpropagation\n",
        "    #Calculation of Gradient\n",
        "    loss.backward()\n",
        "    #This would update the weights and biases\n",
        "    optimizer1.step()\n",
        "    #This would zero down the gradients so that they arent added up in next step\n",
        "    optimizer1.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u__E7Qo_U4YS"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    #Set model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    #Mean or average of loss\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return 100*correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "COETMezjeWOL"
      },
      "outputs": [],
      "source": [
        "learningRate = 1e-1\n",
        "batchSize  = 128\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LpRbqE71lXBl"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=batchSize,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batchSize,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p6WB1SJ0h2eH"
      },
      "outputs": [],
      "source": [
        "#Combines LogSoftmax and NLLLoss - Negativce log likelihood\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "optimizer1 = torch.optim.SGD(model.parameters(),lr = learningRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtPnVfzsVubJ",
        "outputId": "079dc18d-77ac-4de5-f8e4-22d5dcf43cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.605356  [  128/60000]\n",
            "loss: 0.555008  [12928/60000]\n",
            "loss: 0.415822  [25728/60000]\n",
            "loss: 0.444401  [38528/60000]\n",
            "loss: 0.516280  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 0.485648 \n",
            "\n",
            "Model saved with accuracy: 82.41%\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.365725  [  128/60000]\n",
            "loss: 0.381182  [12928/60000]\n",
            "loss: 0.416659  [25728/60000]\n",
            "loss: 0.366070  [38528/60000]\n",
            "loss: 0.525844  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.451012 \n",
            "\n",
            "Model saved with accuracy: 83.52%\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.467451  [  128/60000]\n",
            "loss: 0.429962  [12928/60000]\n",
            "loss: 0.433258  [25728/60000]\n",
            "loss: 0.402911  [38528/60000]\n",
            "loss: 0.385085  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 0.411682 \n",
            "\n",
            "Model saved with accuracy: 84.97%\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.458657  [  128/60000]\n",
            "loss: 0.380005  [12928/60000]\n",
            "loss: 0.377647  [25728/60000]\n",
            "loss: 0.359906  [38528/60000]\n",
            "loss: 0.300551  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.401724 \n",
            "\n",
            "Model saved with accuracy: 85.43%\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.365437  [  128/60000]\n",
            "loss: 0.432623  [12928/60000]\n",
            "loss: 0.318917  [25728/60000]\n",
            "loss: 0.357480  [38528/60000]\n",
            "loss: 0.419748  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.394603 \n",
            "\n",
            "Model saved with accuracy: 85.92%\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.379606  [  128/60000]\n",
            "loss: 0.310626  [12928/60000]\n",
            "loss: 0.351700  [25728/60000]\n",
            "loss: 0.249673  [38528/60000]\n",
            "loss: 0.273202  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.385169 \n",
            "\n",
            "Model saved with accuracy: 86.12%\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.203678  [  128/60000]\n",
            "loss: 0.373004  [12928/60000]\n",
            "loss: 0.288161  [25728/60000]\n",
            "loss: 0.203885  [38528/60000]\n",
            "loss: 0.341087  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.411976 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.465743  [  128/60000]\n",
            "loss: 0.275061  [12928/60000]\n",
            "loss: 0.224728  [25728/60000]\n",
            "loss: 0.428389  [38528/60000]\n",
            "loss: 0.276834  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.375325 \n",
            "\n",
            "Model saved with accuracy: 86.52%\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.274361  [  128/60000]\n",
            "loss: 0.281295  [12928/60000]\n",
            "loss: 0.286645  [25728/60000]\n",
            "loss: 0.344515  [38528/60000]\n",
            "loss: 0.290166  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.392913 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.311760  [  128/60000]\n",
            "loss: 0.372521  [12928/60000]\n",
            "loss: 0.358998  [25728/60000]\n",
            "loss: 0.317664  [38528/60000]\n",
            "loss: 0.312782  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.372013 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.224150  [  128/60000]\n",
            "loss: 0.378259  [12928/60000]\n",
            "loss: 0.328706  [25728/60000]\n",
            "loss: 0.199658  [38528/60000]\n",
            "loss: 0.293367  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.352459 \n",
            "\n",
            "Model saved with accuracy: 87.39%\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.235080  [  128/60000]\n",
            "loss: 0.363807  [12928/60000]\n",
            "loss: 0.341811  [25728/60000]\n",
            "loss: 0.256083  [38528/60000]\n",
            "loss: 0.306205  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.372985 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.328114  [  128/60000]\n",
            "loss: 0.277783  [12928/60000]\n",
            "loss: 0.318391  [25728/60000]\n",
            "loss: 0.173795  [38528/60000]\n",
            "loss: 0.333177  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.348532 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.244468  [  128/60000]\n",
            "loss: 0.257286  [12928/60000]\n",
            "loss: 0.392486  [25728/60000]\n",
            "loss: 0.336455  [38528/60000]\n",
            "loss: 0.247999  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.343944 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.325636  [  128/60000]\n",
            "loss: 0.294833  [12928/60000]\n",
            "loss: 0.281513  [25728/60000]\n",
            "loss: 0.267457  [38528/60000]\n",
            "loss: 0.192759  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.362814 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.329372  [  128/60000]\n",
            "loss: 0.244661  [12928/60000]\n",
            "loss: 0.238658  [25728/60000]\n",
            "loss: 0.235936  [38528/60000]\n",
            "loss: 0.314098  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.363138 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.270093  [  128/60000]\n",
            "loss: 0.222249  [12928/60000]\n",
            "loss: 0.335856  [25728/60000]\n",
            "loss: 0.167298  [38528/60000]\n",
            "loss: 0.429913  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.337885 \n",
            "\n",
            "Model saved with accuracy: 87.96%\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.227843  [  128/60000]\n",
            "loss: 0.223431  [12928/60000]\n",
            "loss: 0.133846  [25728/60000]\n",
            "loss: 0.246234  [38528/60000]\n",
            "loss: 0.303929  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.340660 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.246786  [  128/60000]\n",
            "loss: 0.372520  [12928/60000]\n",
            "loss: 0.240111  [25728/60000]\n",
            "loss: 0.218733  [38528/60000]\n",
            "loss: 0.287627  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.329434 \n",
            "\n",
            "Model saved with accuracy: 88.29%\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.274902  [  128/60000]\n",
            "loss: 0.246909  [12928/60000]\n",
            "loss: 0.302865  [25728/60000]\n",
            "loss: 0.227363  [38528/60000]\n",
            "loss: 0.266743  [51328/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.342106 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "maxAccuracy = 0.0\n",
        "modelPath = \"/content/drive/MyDrive/Colab Notebooks/MTCS-205/Assignments/Assignment-1-Model/maxAccuracyModel.pth\"\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, lossFn, optimizer1)\n",
        "    #test_loop(test_dataloader, model, lossFn)\n",
        "    accuracy = test_loop(test_dataloader, model, lossFn)\n",
        "    if accuracy > maxAccuracy :\n",
        "      maxAccuracy = accuracy\n",
        "      torch.save(model.state_dict(), modelPath)\n",
        "      print(f\"Model saved with accuracy: {maxAccuracy:.2f}%\")\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisations in Tensorboard"
      ],
      "metadata": {
        "id": "3AF_Hx4r-Gw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnGGD1FMvnl9"
      },
      "outputs": [],
      "source": [
        "\"\"\"logsPath = \"/content/drive/MyDrive/Colab Notebooks/MTCS-205/Assignments/logs\"\n",
        "writer = SummaryWriter(logsPath)\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ujvSXRfnvVZcmyvZZS0Ekyg_2cDDGWg7",
      "authorship_tag": "ABX9TyMoShIqIyn8rlbeOuO/z+r6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}